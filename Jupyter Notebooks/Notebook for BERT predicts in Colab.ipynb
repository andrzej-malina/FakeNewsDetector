{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbQo5QPSWTLU"
   },
   "source": [
    "Poniższy notebook pokazuje jak wykorzystać darmowe GPU na Google Colab aby wyliczyć predykcje z modelu BERT. Przed uruchomieniem notebooka warto upewnić się, że włączyliśmy GPU w Colabie wybierając ścieżkę `Runtime`, `Change runtime type`, `GPU` i kilkając przycisk `Save`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cW5QmuhUMxZ"
   },
   "source": [
    "# Parametry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vo-umXqyVDy6"
   },
   "source": [
    "Najpierw wprowadzamy szczegóły modelu BERT, którego chcemy użyć (jest kilka rodzajów BERTa, które różnią się złożonością architektury). Im większy BERT tym większa moc obliczeniowa (i czas) potrzebny do wyliczenia predykcji.\n",
    "Szczegóły możemy przeczytać na [repo BERTA na git-hub](https://github.com/google-research/bert). Po kliknięciu PPM na wybrany model można skopiować link, który zawiera info na temat daty (`date`) i nazwy (`name`) modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NxeY_4rBWD9w"
   },
   "outputs": [],
   "source": [
    "bert_model_name = 'uncased_L-12_H-128_A-2'\n",
    "bert_model_date = '2018_10_18'\n",
    "bert_model_path = f'https://storage.googleapis.com/bert_models/{bert_model_date}/{bert_model_name}.zip'\n",
    "uncased=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKAhfA-cVwc2"
   },
   "source": [
    "Następnie należy określić ścieżki dostępu, które będą używane w notebooku:\n",
    "- ścieżka z parametrami modelu (model data),\n",
    "- ścieżka z danymi wejściowymi (input),\n",
    "- ścieżka gdzie zapisywane będą wyniki predykcji (output)\n",
    "\n",
    "Ścieżka `./drive/My Drive/` wskazuje na miejsce na Twoim dysku Google Drive gdzie można stworzyć odpowiednie foldery do przechowywania danych wejściowych i wyjściowych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cKjR19LvUwj8"
   },
   "outputs": [],
   "source": [
    "model_dir = f'./{bert_model_name}'\n",
    "\n",
    "data_dir = './drive/My Drive/Colab Notebooks/input'\n",
    "train_dir = f'{data_dir}/train_fake.csv'\n",
    "test_dir = f'{data_dir}/test_fake.csv'\n",
    "\n",
    "out_dir = './drive/My Drive/Colab Notebooks/output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OM5OIHTTysB"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mU2klIOaT7ha"
   },
   "source": [
    "## Montaż google drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2l2sEh2RX9j-"
   },
   "source": [
    "Aby uzyskać dostęp do folderów znajdujących się w środku, musisz zamontować dysk Google Drive. Po uruchomieniu tej komórki zobaczysz link umożliwiający autoryzację dostępu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f9htjq7LWQeo",
    "outputId": "fe4e2cc9-8c03-4197-c475-aa2106d0830c"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAFXdMQVYMXN"
   },
   "source": [
    "## Pobranie plików z parametrami modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kjBSyiQlWMNn",
    "outputId": "50c4f88f-4bc5-4c0b-c28a-517e38d98d3f"
   },
   "outputs": [],
   "source": [
    "!wget {bert_model_path}\n",
    "!unzip the file\n",
    "!unzip {bert_model_name}.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6qugUpOYnx_"
   },
   "source": [
    "## Instalacja potrzebnych bibliotek Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o_WqPYNaXBYv",
    "outputId": "a995d5a5-2ebe-4968-e95c-419050882ba3"
   },
   "outputs": [],
   "source": [
    "!pip install keras_bert\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "JmaKZU00WD9i"
   },
   "source": [
    "# Import bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DEmx5yddWD9j"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QAMw1OeNZFFw"
   },
   "outputs": [],
   "source": [
    "from keras_bert import load_trained_model_from_checkpoint\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "fID5q14RWD9s"
   },
   "source": [
    "# Funkcje pomocnicze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B9ITU0kiWD9s"
   },
   "outputs": [],
   "source": [
    "#funkcja wyświetlająca pełny dataframe\n",
    "def display_all(df, num_rows=10000, num_cols=10000, col_width=-1):\n",
    "    with pd.option_context('display.max_rows', num_rows, 'display.max_columns', num_cols, 'display.max_colwidth', -1):\n",
    "        display(df)\n",
    "        \n",
    "#funcja do inicjalizacji modelu BERT\n",
    "def init_tokenizer_and_load_bert_model(model_dir, model_name, model_trainable=True, lowercase=True):\n",
    "\n",
    "    vocab_path = f'{model_dir}/vocab.txt'\n",
    "    config_path = f'{model_dir}/bert_config.json'\n",
    "    checkpoint_path = f'{model_dir}/bert_model.ckpt'\n",
    "    \n",
    "    tokenizer = BertTokenizer(vocab_path, do_lower_case=lowercase)\n",
    "    model = load_trained_model_from_checkpoint(config_path, checkpoint_path, trainable=model_trainable)\n",
    "    \n",
    "    print('vocab_size:', len(tokenizer.vocab))\n",
    "    print('loaded model: ', model_name)\n",
    "    \n",
    "    return tokenizer, model\n",
    "\n",
    "#funckja wyliczająca wektory input_ids, token_type_ids, attention_mask specyficzne dla modelu BERT (tokenizacja)\n",
    "#funkcja zwraca wektory w postaci słownika\n",
    "def get_bert_vectors(tokenizer, df, col_name, vector_length=512):\n",
    "    tokenize = lambda sentence: tokenizer.encode_plus(sentence, max_length=vector_length, padding='max_length', truncation=True)\n",
    "    df[f'{col_name}_tokens'] = df[col_name].map(tokenize)\n",
    "\n",
    "    df[f'{col_name}_input_ids'] = df[f'{col_name}_tokens'].map(lambda x: x['input_ids'])\n",
    "    df[f'{col_name}_token_type_ids'] = df[f'{col_name}_tokens'].map(lambda x: x['token_type_ids'])\n",
    "    df[f'{col_name}_attention_mask'] = df[f'{col_name}_tokens'].map(lambda x: x['attention_mask'])\n",
    "    \n",
    "    input_ids = np.stack(df[f'{col_name}_input_ids'])\n",
    "    token_type_ids = np.stack(df[f'{col_name}_token_type_ids'])\n",
    "    attention_mask = np.stack(df[f'{col_name}_attention_mask'])\n",
    "    vectors = {'input_ids': input_ids, 'token_type_ids': token_type_ids, 'attention_mask': attention_mask}\n",
    "    \n",
    "    return vectors\n",
    "\n",
    "#funkcja wyliczająca predykcje klasyfikacji modelu BERT w batchach, aby nie wyczerpać pamięci RAM\n",
    "def bert_predict_in_batches(vectors, num_batches, output_shape):\n",
    "\n",
    "  vector_input_ids_batches = np.array_split(vectors['input_ids'], num_batches)\n",
    "  vector_token_type_ids_batches = np.array_split(vectors['token_type_ids'], num_batches)\n",
    "  vector_attention_mask_batches = np.array_split(vectors['attention_mask'], num_batches)\n",
    "\n",
    "  X = np.array([]).reshape((0, output_shape))\n",
    "\n",
    "  input_vectors = zip(vector_input_ids_batches, vector_token_type_ids_batches, vector_attention_mask_batches)\n",
    "  for input_ids, token_type_ids, attention_mask in input_vectors:\n",
    "    all_vectors = (input_ids, token_type_ids, attention_mask)\n",
    "    predictions = bert_model.predict(all_vectors, verbose=1)\n",
    "\n",
    "    X_batch = predictions[:, 0, :]\n",
    "    print('current predictions shape: ', X_batch.shape)\n",
    "    X = np.concatenate([X, X_batch])\n",
    "    print('all predictions shape: ', X.shape)\n",
    "\n",
    "  return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ircroN0wWD91"
   },
   "source": [
    "# Wczytanie danych treningowych i testowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QBfpIHf6WD92",
    "outputId": "80d6f22b-2b93-4bc8-f86d-8d6545267c1e"
   },
   "outputs": [],
   "source": [
    "train_fake = pd.read_csv(train_dir)\n",
    "train_fake['is_fake'] = train_fake['is_fake'].astype('int8')\n",
    "test_fake = pd.read_csv(test_dir)\n",
    "\n",
    "train_fake.shape, test_fake.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvKBcS0_C8Lk"
   },
   "source": [
    "Niektóre dane są puste (nan), więc zamieniamy je na string 'unknown', aby móc wyliczyć predykcje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NOUbrk1T7lTv"
   },
   "outputs": [],
   "source": [
    "train_fake.fillna('unknown', inplace=True)\n",
    "test_fake.fillna('unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oeVDToVpWD95"
   },
   "source": [
    "# Model BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1EPmFeS4WD95",
    "outputId": "caf7c3e1-327b-4090-d147-8682d90b99bc"
   },
   "outputs": [],
   "source": [
    "tokenizer, bert_model = init_tokenizer_and_load_bert_model(model_dir, bert_model_name, model_trainable=True, lowercase=uncased)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dMh8y0DMWD98"
   },
   "source": [
    "## Tokenizacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NtPy55ueL3Xf",
    "outputId": "29e3cf99-458e-483c-e9b3-78cae8789af5"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_title_vectors = get_bert_vectors(tokenizer, train_fake, 'title', vector_length=512)\n",
    "[vec.shape for vec in train_title_vectors.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0nS_5uGmWD-F",
    "outputId": "5e1c8956-feb4-4e22-af71-00f98d96f709"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_text_vectors = get_bert_vectors(tokenizer, train_fake, 'text', vector_length=512)\n",
    "[vec.shape for vec in train_text_vectors.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sTEThvwh-5Ps",
    "outputId": "ec457cde-b1fc-457f-86c5-80849f5951b6"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "test_title_vectors = get_bert_vectors(tokenizer, test_fake, 'title', vector_length=512)\n",
    "[vec.shape for vec in test_title_vectors.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G_q1RirB-4-4",
    "outputId": "67c341f9-a383-49c7-b99c-d5ae8845ca9d"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "test_text_vectors = get_bert_vectors(tokenizer, test_fake, 'text', vector_length=512)\n",
    "[vec.shape for vec in test_text_vectors.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sEwRH4bQWD-N"
   },
   "source": [
    "## Wyliczenie predykcji i zapisanie wyników"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_output_shape = bert_model.layers[-1].output_shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4WauoSt-RNO"
   },
   "outputs": [],
   "source": [
    "train_X_title = bert_predict_in_batches(train_title_vectors, 5, bert_output_shape)\n",
    "np.save(f'{out_dir}/train_X_title_{bert_model_name}.npy', train_X_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HLrb6UkD-nQn"
   },
   "outputs": [],
   "source": [
    "train_X_text = bert_predict_in_batches(train_text_vectors, 15, bert_output_shape)\n",
    "np.save(f'{out_dir}/train_X_text_{bert_model_name}.npy', train_X_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vAkVrODw_I1-"
   },
   "outputs": [],
   "source": [
    "test_X_title = bert_predict_in_batches(test_title_vectors, 5, bert_output_shape)\n",
    "np.save(f'{out_dir}/test_X_title_{bert_model_name}.npy', test_X_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E8Y2A0Sq_Ihv"
   },
   "outputs": [],
   "source": [
    "test_X_text = bert_predict_in_batches(test_text_vectors, 15, bert_output_shape)\n",
    "np.save(f'{out_dir}/test_X_text_{bert_model_name}.npy', test_X_text)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "modeling_bert.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0b4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
